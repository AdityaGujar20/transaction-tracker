{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f46ea3f",
   "metadata": {},
   "source": [
    "## Kotak Bank Statement Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d018f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: bank-statements/kotak.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Jun 12, 2025 10:49:24 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
      "WARNING: No Unicode mapping for .notdef (13) in font Roboto\n",
      "Jun 12, 2025 10:49:24 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
      "WARNING: No Unicode mapping for .notdef (13) in font Courier\n",
      "Jun 12, 2025 10:49:25 AM org.apache.pdfbox.rendering.TTFGlyph2D getPathForGID\n",
      "WARNING: No glyph for 13 in font Roboto\n",
      "Jun 12, 2025 10:49:25 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "Jun 12, 2025 10:49:26 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "Jun 12, 2025 10:49:26 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "Jun 12, 2025 10:49:27 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "Jun 12, 2025 10:49:27 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "Jun 12, 2025 10:49:27 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
      "WARNING: No glyph for code 13 (.notdef) in font Courier\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 tables using tabula\n",
      "Table 1: 24 rows, 6 columns\n",
      "Table 2: 40 rows, 6 columns\n",
      "Table 3: 41 rows, 6 columns\n",
      "Table 4: 13 rows, 6 columns\n",
      "Combined table: 118 rows, 6 columns\n",
      "Combined table saved to: extracted_tables_combined.csv\n",
      "\n",
      "Table Info:\n",
      "Shape: (118, 6)\n",
      "Columns: ['BALANCE', 'CHEQUE/REFERENCE#', 'CREDIT', 'DATE', 'DEBIT', 'TRANSACTION_DETAILS']\n",
      "\n",
      "First few rows:\n",
      "    BALANCE CHEQUE/REFERENCE#     CREDIT          DATE    DEBIT  \\\n",
      "0  1,763.20               NaN  +1,763.20  01 Dec, 2024      NaN   \n",
      "1  1,358.20  UPI-433665205422        NaN  01 Dec, 2024  -405.00   \n",
      "2  1,464.20  UPI-433669845433    +106.00  01 Dec, 2024      NaN   \n",
      "3  1,548.20  UPI-433669943628     +84.00  01 Dec, 2024      NaN   \n",
      "4  1,575.20  UPI-433670096561     +27.00  01 Dec, 2024      NaN   \n",
      "\n",
      "                                 TRANSACTION_DETAILS  \n",
      "0                                OPENING BALANCE ...  \n",
      "1  UPI/RAMESHWARAM ENT/433658302817/Payment for\\r674  \n",
      "2                    UPI/KRISHKUMAR/433649942953/UPI  \n",
      "3                    UPI/KRISHKUMAR/433650069544/UPI  \n",
      "4               UPI/SHAURYAPRATAPSI/433665658570/UPI  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tabula\n",
    "import PyPDF2\n",
    "import re\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class BankStatementTableExtractor:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.tables = []\n",
    "        \n",
    "    def extract_tables_with_tabula(self) -> List[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Extract tables using tabula-py library\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tables = tabula.read_pdf(\n",
    "                self.pdf_path, \n",
    "                pages='all', \n",
    "                multiple_tables=True,\n",
    "                pandas_options={'header': 0}\n",
    "            )\n",
    "            \n",
    "            print(f\"Found {len(tables)} tables using tabula\")\n",
    "            return tables\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting tables with tabula: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_transaction_table_from_text(self, text: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract transaction table from text using regex patterns\n",
    "        \"\"\"\n",
    "        transaction_pattern = r'(\\d{2}\\s+\\w{3},\\s+\\d{4})\\s+(.*?)\\s+([\\w-]+)\\s+([-+]?\\d+\\.?\\d*)\\s+([-+]?\\d+\\.?\\d*)\\s+(\\d+\\.?\\d*)'\n",
    "        \n",
    "        matches = re.findall(transaction_pattern, text)\n",
    "        \n",
    "        if matches:\n",
    "            df = pd.DataFrame(matches, columns=[\n",
    "                'DATE', 'TRANSACTION_DETAILS', 'CHEQUE_REFERENCE', \n",
    "                'DEBIT', 'CREDIT', 'BALANCE'\n",
    "            ])\n",
    "            \n",
    "            for col in ['DEBIT', 'CREDIT', 'BALANCE']:\n",
    "                df[col] = pd.to_numeric(df[col].replace('', '0'), errors='coerce')\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    def extract_tables_from_text(self) -> List[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Extract tables by parsing PDF text content\n",
    "        \"\"\"\n",
    "        tables = []\n",
    "        \n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                \n",
    "                for page in pdf_reader.pages:\n",
    "                    text = page.extract_text()\n",
    "                    \n",
    "                    if 'DATE TRANSACTION DETAILS' in text:\n",
    "                        lines = text.split('\\n')\n",
    "                        table_data = []\n",
    "                        in_table = False\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            if 'DATE TRANSACTION DETAILS' in line:\n",
    "                                in_table = True\n",
    "                                continue\n",
    "                            elif 'SUMMARY' in line or 'Page' in line:\n",
    "                                in_table = False\n",
    "                                continue\n",
    "                            \n",
    "                            if in_table and line.strip():\n",
    "                                parts = line.strip().split()\n",
    "                                if len(parts) >= 6 and re.match(r'\\d{2}\\s+\\w{3}', line):\n",
    "                                    date_match = re.match(r'(\\d{2}\\s+\\w{3},\\s+\\d{4})', line)\n",
    "                                    if date_match:\n",
    "                                        date = date_match.group(1)\n",
    "                                        rest = line[date_match.end():].strip()\n",
    "                                        \n",
    "                                        balance_match = re.search(r'(\\d+\\.\\d+)$', rest)\n",
    "                                        if balance_match:\n",
    "                                            balance = balance_match.group(1)\n",
    "                                            \n",
    "                                            amounts_section = rest[:balance_match.start()].strip()\n",
    "                                            amounts = re.findall(r'[-+]?\\d+\\.\\d+', amounts_section)\n",
    "                                            \n",
    "                                            debit = amounts[-2] if len(amounts) >= 2 and amounts[-2].startswith('-') else '0'\n",
    "                                            credit = amounts[-1] if len(amounts) >= 1 and not amounts[-1].startswith('-') else '0'\n",
    "                                            \n",
    "                                            details_section = amounts_section\n",
    "                                            for amt in amounts:\n",
    "                                                details_section = details_section.replace(amt, '')\n",
    "                                            \n",
    "                                            reference_match = re.search(r'(UPI-\\w+|NEFT\\w+-\\w+|\\w+-\\w+)$', details_section)\n",
    "                                            reference = reference_match.group(1) if reference_match else ''\n",
    "                                            \n",
    "                                            transaction_details = details_section.replace(reference, '').strip()\n",
    "                                            \n",
    "                                            table_data.append([\n",
    "                                                date, transaction_details, reference, \n",
    "                                                debit, credit, balance\n",
    "                                            ])\n",
    "                        \n",
    "                        if table_data:\n",
    "                            df = pd.DataFrame(table_data, columns=[\n",
    "                                'DATE', 'TRANSACTION_DETAILS', 'CHEQUE_REFERENCE',\n",
    "                                'DEBIT', 'CREDIT', 'BALANCE'\n",
    "                            ])\n",
    "                            \n",
    "                            for col in ['DEBIT', 'CREDIT', 'BALANCE']:\n",
    "                                df[col] = pd.to_numeric(df[col].replace('', '0'), errors='coerce')\n",
    "                            \n",
    "                            tables.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting from text: {e}\")\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    def clean_and_standardize_tables(self, tables: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Clean and standardize table formats\n",
    "        \"\"\"\n",
    "        cleaned_tables = []\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            if table.empty:\n",
    "                continue\n",
    "                \n",
    "            table = table.dropna(how='all')\n",
    "            \n",
    "            if len(table) < 2:\n",
    "                continue\n",
    "            \n",
    "            table.columns = [col.strip().upper().replace(' ', '_') for col in table.columns]\n",
    "            \n",
    "            cleaned_tables.append(table)\n",
    "            print(f\"Table {i+1}: {table.shape[0]} rows, {table.shape[1]} columns\")\n",
    "        \n",
    "        return cleaned_tables\n",
    "    \n",
    "    def stack_tables_vertically(self, tables: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Stack all tables vertically into a single DataFrame\n",
    "        \"\"\"\n",
    "        if not tables:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        all_columns = set()\n",
    "        for table in tables:\n",
    "            all_columns.update(table.columns)\n",
    "        \n",
    "        standardized_tables = []\n",
    "        for table in tables:\n",
    "            for col in all_columns:\n",
    "                if col not in table.columns:\n",
    "                    table[col] = np.nan\n",
    "            \n",
    "            table = table.reindex(columns=sorted(all_columns))\n",
    "            standardized_tables.append(table)\n",
    "        \n",
    "        combined_table = pd.concat(standardized_tables, ignore_index=True)\n",
    "        \n",
    "        print(f\"Combined table: {combined_table.shape[0]} rows, {combined_table.shape[1]} columns\")\n",
    "        return combined_table\n",
    "    \n",
    "    def process_pdf(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Main method to process the PDF and return stacked tables\n",
    "        \"\"\"\n",
    "        print(f\"Processing PDF: {self.pdf_path}\")\n",
    "        \n",
    "        tables = self.extract_tables_with_tabula()\n",
    "        \n",
    "        if not tables or all(table.empty for table in tables):\n",
    "            print(\"Tabula extraction failed, trying text extraction...\")\n",
    "            tables = self.extract_tables_from_text()\n",
    "        \n",
    "        cleaned_tables = self.clean_and_standardize_tables(tables)\n",
    "        \n",
    "        final_table = self.stack_tables_vertically(cleaned_tables)\n",
    "        \n",
    "        return final_table\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"bank-statements/kotak.pdf\"\n",
    "    \n",
    "    try:\n",
    "        extractor = BankStatementTableExtractor(pdf_path)\n",
    "        combined_table = extractor.process_pdf()\n",
    "        \n",
    "        if not combined_table.empty:\n",
    "            output_file = \"extracted_tables_combined.csv\"\n",
    "            combined_table.to_csv(output_file, index=False)\n",
    "            print(f\"Combined table saved to: {output_file}\")\n",
    "            \n",
    "            print(\"\\nTable Info:\")\n",
    "            print(f\"Shape: {combined_table.shape}\")\n",
    "            print(f\"Columns: {list(combined_table.columns)}\")\n",
    "            print(\"\\nFirst few rows:\")\n",
    "            print(combined_table.head())\n",
    "            \n",
    "        else:\n",
    "            print(\"No tables were extracted from the PDF\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "def extract_with_camelot(pdf_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Alternative method using camelot-py library\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import camelot\n",
    "        \n",
    "        tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "        \n",
    "        print(f\"Found {len(tables)} tables with camelot\")\n",
    "        \n",
    "        dfs = [table.df for table in tables]\n",
    "        \n",
    "        if dfs:\n",
    "            combined = pd.concat(dfs, ignore_index=True)\n",
    "            return combined\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"Camelot not installed. Install with: pip install camelot-py[cv]\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with camelot: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_bank_statement():\n",
    "    \"\"\"\n",
    "    Specific function for processing the kotak bank statement\n",
    "    \"\"\"\n",
    "    pdf_path = \"bank-statements/kotak.pdf\"\n",
    "    \n",
    "    print(\"For the Kotak bank statement, use the BankStatementTableExtractor class above\")\n",
    "    print(\"It will handle the specific format and extract transaction tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65f449e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>CHEQUE/REFERENCE#</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DEBIT</th>\n",
       "      <th>TRANSACTION_DETAILS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,763.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1,763.20</td>\n",
       "      <td>01 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPENING BALANCE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,358.20</td>\n",
       "      <td>UPI-433665205422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Dec, 2024</td>\n",
       "      <td>-405.00</td>\n",
       "      <td>UPI/RAMESHWARAM ENT/433658302817/Payment for\\r674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,464.20</td>\n",
       "      <td>UPI-433669845433</td>\n",
       "      <td>+106.00</td>\n",
       "      <td>01 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPI/KRISHKUMAR/433649942953/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,548.20</td>\n",
       "      <td>UPI-433669943628</td>\n",
       "      <td>+84.00</td>\n",
       "      <td>01 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPI/KRISHKUMAR/433650069544/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,575.20</td>\n",
       "      <td>UPI-433670096561</td>\n",
       "      <td>+27.00</td>\n",
       "      <td>01 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPI/SHAURYAPRATAPSI/433665658570/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2,485.47</td>\n",
       "      <td>UPI-436525427708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30 Dec, 2024</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>UPI/Mr. SHONN SUKHE/436561214143/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2,245.47</td>\n",
       "      <td>UPI-436652806258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 Dec, 2024</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>UPI/CAFE COFFEE HUT/436696902597/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2,405.47</td>\n",
       "      <td>UPI-436652867072</td>\n",
       "      <td>160.0</td>\n",
       "      <td>31 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPI/SOHAMSAMIRKADAM/436669906609/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2,365.47</td>\n",
       "      <td>UPI-436675770872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 Dec, 2024</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>UPI/MOHINI SANDEEP /436690262241/UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2,391.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31 Dec, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Int.Pd:6845525302:01-10-2024 to 31-12-2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BALANCE CHEQUE/REFERENCE#     CREDIT          DATE    DEBIT  \\\n",
       "0    1,763.20               NaN  +1,763.20  01 Dec, 2024      NaN   \n",
       "1    1,358.20  UPI-433665205422        NaN  01 Dec, 2024  -405.00   \n",
       "2    1,464.20  UPI-433669845433    +106.00  01 Dec, 2024      NaN   \n",
       "3    1,548.20  UPI-433669943628     +84.00  01 Dec, 2024      NaN   \n",
       "4    1,575.20  UPI-433670096561     +27.00  01 Dec, 2024      NaN   \n",
       "..        ...               ...        ...           ...      ...   \n",
       "113  2,485.47  UPI-436525427708        NaN  30 Dec, 2024    -70.0   \n",
       "114  2,245.47  UPI-436652806258        NaN  31 Dec, 2024   -240.0   \n",
       "115  2,405.47  UPI-436652867072      160.0  31 Dec, 2024      NaN   \n",
       "116  2,365.47  UPI-436675770872        NaN  31 Dec, 2024    -40.0   \n",
       "117  2,391.47               NaN       26.0  31 Dec, 2024      NaN   \n",
       "\n",
       "                                   TRANSACTION_DETAILS  \n",
       "0                                  OPENING BALANCE ...  \n",
       "1    UPI/RAMESHWARAM ENT/433658302817/Payment for\\r674  \n",
       "2                      UPI/KRISHKUMAR/433649942953/UPI  \n",
       "3                      UPI/KRISHKUMAR/433650069544/UPI  \n",
       "4                 UPI/SHAURYAPRATAPSI/433665658570/UPI  \n",
       "..                                                 ...  \n",
       "113               UPI/Mr. SHONN SUKHE/436561214143/UPI  \n",
       "114               UPI/CAFE COFFEE HUT/436696902597/UPI  \n",
       "115               UPI/SOHAMSAMIRKADAM/436669906609/UPI  \n",
       "116               UPI/MOHINI SANDEEP /436690262241/UPI  \n",
       "117         Int.Pd:6845525302:01-10-2024 to 31-12-2024  \n",
       "\n",
       "[118 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"extracted_tables_combined.csv\")\n",
    "# Display the first few rows of the DataFrame   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77381b",
   "metadata": {},
   "source": [
    "## Rule based categorization by \"Transaction Details\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94088ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DATE                                TRANSACTION_DETAILS  \\\n",
      "0    01 Dec, 2024                                OPENING BALANCE ...   \n",
      "1    01 Dec, 2024  UPI/RAMESHWARAM ENT/433658302817/Payment for\\r674   \n",
      "2    01 Dec, 2024                    UPI/KRISHKUMAR/433649942953/UPI   \n",
      "3    01 Dec, 2024                    UPI/KRISHKUMAR/433650069544/UPI   \n",
      "4    01 Dec, 2024               UPI/SHAURYAPRATAPSI/433665658570/UPI   \n",
      "..            ...                                                ...   \n",
      "113  30 Dec, 2024               UPI/Mr. SHONN SUKHE/436561214143/UPI   \n",
      "114  31 Dec, 2024               UPI/CAFE COFFEE HUT/436696902597/UPI   \n",
      "115  31 Dec, 2024               UPI/SOHAMSAMIRKADAM/436669906609/UPI   \n",
      "116  31 Dec, 2024               UPI/MOHINI SANDEEP /436690262241/UPI   \n",
      "117  31 Dec, 2024         Int.Pd:6845525302:01-10-2024 to 31-12-2024   \n",
      "\n",
      "        CREDIT    DEBIT       CATEGORY  \n",
      "0    +1,763.20      NaN  Miscellaneous  \n",
      "1          NaN  -405.00  Miscellaneous  \n",
      "2      +106.00      NaN  Miscellaneous  \n",
      "3       +84.00      NaN  Miscellaneous  \n",
      "4       +27.00      NaN  Miscellaneous  \n",
      "..         ...      ...            ...  \n",
      "113        NaN    -70.0  Miscellaneous  \n",
      "114        NaN   -240.0           Food  \n",
      "115      160.0      NaN  Miscellaneous  \n",
      "116        NaN    -40.0  Miscellaneous  \n",
      "117       26.0      NaN  Miscellaneous  \n",
      "\n",
      "[118 rows x 5 columns]\n",
      "\n",
      "Summary by Category:\n",
      "                                                          CREDIT  \\\n",
      "CATEGORY                                                           \n",
      "Entertainment                                                  0   \n",
      "Food                                          +30.00+10.00+20.00   \n",
      "Health                                                         0   \n",
      "Income                 +1.00+1,500.00+1,500.00+3,500.00+1,500.00   \n",
      "Investments                                                    0   \n",
      "Miscellaneous  +1,763.20+106.00+84.00+27.00+7,003.00+181.00+4...   \n",
      "\n",
      "                                                           DEBIT  \\\n",
      "CATEGORY                                                           \n",
      "Entertainment                                          -4,190.00   \n",
      "Food           -60.00-60.00-45.00-30.00-95.0-320.0-72.0-28.0-...   \n",
      "Health         -40.00-25.00-82.00-60.00-20.00-30.00-25.00-35....   \n",
      "Income                                                         0   \n",
      "Investments    -100.00-1,500.00-1,500.00-1,500.00-100.0-100.0...   \n",
      "Miscellaneous  -405.00-50.00-1.00-20.00-20.00-15.00-573.59-20...   \n",
      "\n",
      "               Transaction Count  \n",
      "CATEGORY                          \n",
      "Entertainment                  1  \n",
      "Food                          14  \n",
      "Health                        10  \n",
      "Income                         5  \n",
      "Investments                   10  \n",
      "Miscellaneous                 78  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Define keyword-to-category mapping\n",
    "category_keywords = {\n",
    "    'Food': ['CAFE', 'RESTAURANT', 'JUICE', 'TEA', 'COFFEE', 'MC DONALDS', 'PUNERI MITHAI', 'SUPER'],\n",
    "    'Investments': ['GROWW', 'MUTUALFUND', 'NACH-MUT-DR'],\n",
    "    'Entertainment': ['TRUEVIBEZ'],\n",
    "    'Health': ['BEYOND HEALTH'],\n",
    "    'Income': ['NEFT', 'UPI_CRADJ', 'Int.Pd'],\n",
    "    'Miscellaneous': []  # Default category for unmatched transactions\n",
    "}\n",
    "\n",
    "def categorize_transaction(details):\n",
    "    if not isinstance(details, str) or not details:\n",
    "        return 'Miscellaneous'\n",
    "    \n",
    "    details = details.upper()  # Convert to uppercase for case-insensitive matching\n",
    "    for category, keywords in category_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in details:\n",
    "                return category\n",
    "    return 'Miscellaneous'\n",
    "\n",
    "\n",
    "# Read CSV data\n",
    "df = pd.read_csv(\"extracted_tables_combined.csv\")\n",
    "\n",
    "# Clean data: Remove any leading/trailing whitespace and handle missing values\n",
    "df['TRANSACTION_DETAILS'] = df['TRANSACTION_DETAILS'].fillna('').str.strip()\n",
    "\n",
    "# Apply categorization\n",
    "df['CATEGORY'] = df['TRANSACTION_DETAILS'].apply(categorize_transaction)\n",
    "\n",
    "# Save or display the result\n",
    "# df.to_csv('categorized_transactions.csv', index=False)\n",
    "print(df[['DATE', 'TRANSACTION_DETAILS', 'CREDIT', 'DEBIT', 'CATEGORY']])\n",
    "\n",
    "# Optional: Summarize by category\n",
    "summary = df.groupby('CATEGORY').agg({\n",
    "    'CREDIT': 'sum',\n",
    "    'DEBIT': 'sum',\n",
    "    'TRANSACTION_DETAILS': 'count'\n",
    "}).rename(columns={'TRANSACTION_DETAILS': 'Transaction Count'})\n",
    "print(\"\\nSummary by Category:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ba852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
